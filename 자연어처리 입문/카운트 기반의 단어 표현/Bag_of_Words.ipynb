{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bag of Words.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdbeA2sd9lWeyQrI5Ul+kW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kang-Beom-Seo/Korean-NLP-Practice/blob/main/Bag_of_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xuabOLBr3La"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTQXNGUntjwD"
      },
      "source": [
        "from konlpy.tag import Okt\r\n",
        "import re  \r\n",
        "okt=Okt()  \r\n",
        "\r\n",
        "token=re.sub(\"(\\.)\",\"\",\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\") # ( \\ . ) 이런 기호들을 제거한다.\r\n",
        "# 정규 표현식을 통해 온점을 제거하는 정제 작업입니다.  \r\n",
        "token=okt.morphs(token)  \r\n",
        "# OKT 형태소 분석기를 통해 토큰화 작업을 수행한 뒤에, token에다가 넣습니다.  \r\n",
        "\r\n",
        "word2index={}  \r\n",
        "bow=[]  \r\n",
        "for voca in token:  \r\n",
        "         if voca not in word2index.keys():  \r\n",
        "             word2index[voca]=len(word2index)  \r\n",
        "# token을 읽으면서, word2index에 없는 (not in) 단어는 새로 추가하고, 이미 있는 단어는 넘깁니다.   \r\n",
        "             bow.insert(len(word2index)-1,1)\r\n",
        "# BoW 전체에 전부 기본값 1을 넣어줍니다. 단어의 개수는 최소 1개 이상이기 때문입니다.  \r\n",
        "         else:\r\n",
        "            index=word2index.get(voca) #word2index[voca]와 같음\r\n",
        "# 재등장하는 단어의 인덱스를 받아옵니다.\r\n",
        "            bow[index]=bow[index]+1\r\n",
        "# 재등장한 단어는 해당하는 인덱스의 위치에 1을 더해줍니다. (단어의 개수를 세는 것입니다.)  \r\n",
        "print(word2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqULattauo34"
      },
      "source": [
        "bow #Bag of Words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8i67fEWupag"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "corpus = ['you know I want your love. because I love you.']\r\n",
        "vector = CountVectorizer()\r\n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\r\n",
        "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GJ8xWapxpyF"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "text=[\"Family is not an important thing. It's everything.\"]\r\n",
        "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"]) #불용어를 지정하면 BoW에서 제외된다.\r\n",
        "print(vect.fit_transform(text).toarray()) \r\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN1UM7VMyJA7"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "text=[\"Family is not an important thing. It's everything.\"]\r\n",
        "vect = CountVectorizer(stop_words=\"english\") #자체 제공된 불용어\r\n",
        "print(vect.fit_transform(text).toarray())\r\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YdtFdXGyOqQ"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "text=[\"Family is not an important thing. It's everything.\"]\r\n",
        "sw = stopwords.words(\"english\")\r\n",
        "vect = CountVectorizer(stop_words =sw) #nltk에서 제공하는 불용어\r\n",
        "print(vect.fit_transform(text).toarray()) \r\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGMO5WRXyU8m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
