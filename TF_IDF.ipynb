{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5IOI0X70R3W25IGKKpaJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kang-Beom-Seo/Korean-NLP-Practice/blob/main/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NHm9GDCw5Dl"
      },
      "source": [
        "import pandas as pd # 데이터프레임 사용을 위해\r\n",
        "from math import log # IDF 계산을 위해"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mexWShNn-8Td"
      },
      "source": [
        "docs = [\r\n",
        "  '먹고 싶은 사과',\r\n",
        "  '먹고 싶은 바나나',\r\n",
        "  '길고 노란 바나나 바나나',\r\n",
        "  '저는 과일이 좋아요'\r\n",
        "] \r\n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\r\n",
        "vocab.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MTiJ9NA_DRF"
      },
      "source": [
        "N = len(docs) # 총 문서의 수\r\n",
        "\r\n",
        "def tf(t, d):\r\n",
        "    return d.count(t) #문서에서 단어 t의 개수를 셈.\r\n",
        "\r\n",
        "def idf(t):\r\n",
        "    df = 0\r\n",
        "    for doc in docs:\r\n",
        "        df += t in doc # t in doc => 문서안에 단어 t가 있으면 True(1), 없으면 False(0)이 나오므로 단어 존재시 1이 카운트되고 없으면 카운트 되지 않는다.\r\n",
        "    return log(N/(df + 1))\r\n",
        "\r\n",
        "def tfidf(t, d):\r\n",
        "    return tf(t,d)* idf(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWjjWQ4sAEeF"
      },
      "source": [
        "result = []\r\n",
        "for i in range(N): # 각 문서에 대해서 아래 명령을 수행\r\n",
        "    result.append([])\r\n",
        "    d = docs[i]\r\n",
        "    for j in range(len(vocab)):\r\n",
        "        t = vocab[j]        \r\n",
        "        result[-1].append(tf(t, d)) # result[-1] == result[i]\r\n",
        "\r\n",
        "tf_ = pd.DataFrame(result, columns = vocab)\r\n",
        "tf_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxfAzcBbBzsb"
      },
      "source": [
        "result = []\r\n",
        "for j in range(len(vocab)):\r\n",
        "    t = vocab[j]\r\n",
        "    result.append(idf(t))\r\n",
        "\r\n",
        "idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\r\n",
        "idf_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XfwxwE3Co9d"
      },
      "source": [
        "result = []\r\n",
        "for i in range(N):\r\n",
        "    result.append([])\r\n",
        "    d = docs[i]\r\n",
        "    for j in range(len(vocab)):\r\n",
        "        t = vocab[j]\r\n",
        "\r\n",
        "        result[-1].append(tfidf(t,d))\r\n",
        "\r\n",
        "tfidf_ = pd.DataFrame(result, columns = vocab)\r\n",
        "tfidf_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcmluPzJC1bQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "corpus = [\r\n",
        "    'you know I want your love',\r\n",
        "    'I like you',\r\n",
        "    'what should I do ',    \r\n",
        "]\r\n",
        "vector = CountVectorizer()\r\n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\r\n",
        "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdK5SRgUDFdj"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "corpus = [\r\n",
        "    'you know I want your love',\r\n",
        "    'I like you',\r\n",
        "    'what should I do ',    \r\n",
        "]\r\n",
        "tfidfv = TfidfVectorizer().fit(corpus)\r\n",
        "print(tfidfv.transform(corpus).toarray())\r\n",
        "print(tfidfv.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oYxsU0aDlJT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}