{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "원-핫 인코딩.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYUyRDkm/SENFIvq58lYUh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kang-Beom-Seo/Korean-NLP-Practice/blob/main/%EC%9B%90_%ED%95%AB_%EC%9D%B8%EC%BD%94%EB%94%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwUAUMR4K-To"
      },
      "source": [
        "!pip install konlpy\r\n",
        "from konlpy.tag import Okt  \r\n",
        "okt=Okt()  \r\n",
        "token=okt.morphs(\"나는 자연어 처리를 배운다\") #문장을 형태소 분석하여 토큰화한다.\r\n",
        "print(token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmAT7PUsLKA-"
      },
      "source": [
        "word2index={}\r\n",
        "for voca in token:\r\n",
        "     if voca not in word2index.keys():\r\n",
        "       word2index[voca]=len(word2index) #단어 집합(vocabulary)를 만들었다.\r\n",
        "print(word2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_0p8vZ3Ln61"
      },
      "source": [
        "def one_hot_encoding(word, word2index): #단어가 들어오면 vocabulary에서 찾아서 그에 맞게 one-hot vector로 만들어준다.\r\n",
        "       one_hot_vector = [0]*(len(word2index))\r\n",
        "       index=word2index[word]\r\n",
        "       one_hot_vector[index]=1\r\n",
        "       return one_hot_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A_drGjGL0HL"
      },
      "source": [
        "text=\"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c3eLKlaMSHp"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "\r\n",
        "text=\"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\r\n",
        "\r\n",
        "t = Tokenizer()\r\n",
        "t.fit_on_texts([text])\r\n",
        "print(t.word_index) # 각 단어에 대한 인코딩 결과 출력."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l98dpnWMVmR"
      },
      "source": [
        "sub_text=\"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\r\n",
        "encoded=t.texts_to_sequences([sub_text])[0] #이 메서드는 원래 여러 문장들을 담은 리스트를 받으므로, 리턴결과도 문장들이 인덱스로 변환된다.\r\n",
        "                                            #여기서는 문장이 1개지만, 어쨋든 0번째 문장에 해당하는 것이므로, [0]을 붙인다.\r\n",
        "print(encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nimVp8yiMlDD"
      },
      "source": [
        "one_hot = to_categorical(encoded)\r\n",
        "print(one_hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WfWHDsZNxkP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}